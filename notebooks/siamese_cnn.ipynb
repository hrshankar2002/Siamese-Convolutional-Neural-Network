{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **1: Data Loading And Processing**\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the path to the folder containing the spectrogram images\n",
    "data_dir = r'path to dataset folder'\n",
    "\n",
    "# Define the classes (folder names)\n",
    "classes = os.listdir(data_dir)\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Define the desired width and height for resizing\n",
    "desired_width = 224\n",
    "desired_height = 224\n",
    "\n",
    "# Initialize lists to store spectrogram images and their corresponding labels\n",
    "images_list = []\n",
    "labels_list = []\n",
    "\n",
    "# Iterate through each class folder\n",
    "for class_idx, class_name in enumerate(classes):\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    # Iterate through each spectrogram image in the class folder\n",
    "    for img_name in os.listdir(class_dir):\n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "        # Read the image using OpenCV\n",
    "        img = cv2.imread(img_path)\n",
    "        # Resize the image to the desired dimensions without preserving the aspect ratio\n",
    "        img = cv2.resize(img, (desired_width, desired_height))\n",
    "        # Convert the image to float32 and normalize pixel values to [0, 1]\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        # Append the preprocessed image and its label to the lists\n",
    "        images_list.append(img)\n",
    "        labels_list.append(class_idx)  # Use class index as label\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "images = np.array(images_list)\n",
    "labels = np.array(labels_list)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Shuffle the data\n",
    "indices = np.arange(images.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "images = images[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "# Split the data into training, validation, and test sets (e.g., 80-10-10 split)\n",
    "train_split = int(0.8 * len(images))\n",
    "val_split = int(0.10 * len(images))\n",
    "x_train, y_train = images[:train_split], labels[:train_split]\n",
    "x_val, y_val = images[train_split:train_split + val_split], labels[train_split:train_split + val_split]\n",
    "x_test, y_test = images[train_split + val_split:], labels[train_split + val_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# **2:Siamese Network Architecture:**\"\"\"\n",
    "\n",
    "from keras.layers import Conv2D, Dense, Flatten, Input, MaxPooling2D, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "# Define input shape\n",
    "input_shape = (desired_height, desired_width, 3)  # Assuming images are RGB\n",
    "\n",
    "# Define Siamese CNN architecture\n",
    "input_left = Input(shape=input_shape)\n",
    "input_right = Input(shape=input_shape)\n",
    "\n",
    "# Shared convolutional layers\n",
    "conv1 = Conv2D(32, kernel_size=(3, 3), activation='relu')\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))\n",
    "conv2 = Conv2D(64, kernel_size=(3, 3), activation='relu')\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))\n",
    "flatten = Flatten()\n",
    "\n",
    "# Process left input\n",
    "x1 = conv1(input_left)\n",
    "x1 = pool1(x1)\n",
    "x1 = conv2(x1)\n",
    "x1 = pool2(x1)\n",
    "x1 = flatten(x1)\n",
    "\n",
    "# Process right input\n",
    "x2 = conv1(input_right)\n",
    "x2 = pool1(x2)\n",
    "x2 = conv2(x2)\n",
    "x2 = pool2(x2)\n",
    "x2 = flatten(x2)\n",
    "\n",
    "# Concatenate the processed inputs\n",
    "concatenated = concatenate([x1, x2])\n",
    "\n",
    "# Dense layers for classification\n",
    "dense1 = Dense(128, activation='relu')(concatenated)\n",
    "output = Dense(num_classes, activation='softmax')(dense1)\n",
    "\n",
    "# Create Siamese CNN model\n",
    "siamese_model = Model(inputs=[input_left, input_right], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "siamese_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# **3:Training**\"\"\"\n",
    "\n",
    "# Define number of epochs and batch size\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "# Train the model\n",
    "history = siamese_model.fit(\n",
    "    [x_train, x_train],  # Pass the left and right images as inputs\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=([x_val, x_val], y_val),  # Pass validation data\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# **4:Evaluation**\"\"\"\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    fbeta_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "# Use the trained model to predict classes for the test set\n",
    "y_pred = siamese_model.predict([x_test, x_test])\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "f2 = fbeta_score(y_test, y_pred_classes, average='weighted', beta=2)\n",
    "\n",
    "print(\"Accuracy: %.5f\", accuracy)\n",
    "print(\"Precision: %.5f\", precision)\n",
    "print(\"Recall: %.5f\", recall)\n",
    "print(\"F1-score: %.5f\", f1)\n",
    "print(\"F2-score: %.5f\", f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# **5:Confusion Matrix**\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming y_test and y_pred_classes are defined\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Generate normalized confusion matrix\n",
    "conf_matrix_normalized = confusion_matrix(y_test, y_pred_classes, normalize='true')\n",
    "\n",
    "# Set up subplots to display both matrices side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot normal confusion matrix\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes, ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix (Counts)')\n",
    "axes[0].set_xlabel('Predicted Labels')\n",
    "axes[0].set_ylabel('True Labels')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "sns.heatmap(conf_matrix_normalized, annot=True, fmt='.2f', cmap='Blues', xticklabels=classes, yticklabels=classes, ax=axes[1])\n",
    "axes[1].set_title('Normalized Confusion Matrix (Proportions)')\n",
    "axes[1].set_xlabel('Predicted Labels')\n",
    "axes[1].set_ylabel('True Labels')\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"conf.png\", dpi=650)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# **6:Save the Model**\"\"\"\n",
    "\n",
    "# Define the path where you want to save the model\n",
    "model_path = 'path to saved model'\n",
    "\n",
    "# Save the model\n",
    "siamese_model.save(model_path)\n",
    "print(\"Model saved successfully at:\", model_path)\n",
    "\n",
    "\"\"\"# **7:For loading the model**\"\"\"\n",
    "\n",
    "# from keras.models import load_model\n",
    "# model_path = r'C:\\Users\\AKmoh\\OneDrive\\Desktop\\hari proj never delete\\ecgmini\\expnew\\latestmodel2.keras'\n",
    "# # Load the saved model\n",
    "# loaded_model = load_model(model_path)\n",
    "\n",
    "# Use the loaded model for inference or further training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# **8:PREDICTION**\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the external spectrogram\n",
    "external_spectrogram_path = 'path to test data'\n",
    "external_spectrogram = cv2.imread(external_spectrogram_path)\n",
    "\n",
    "# Preprocess the external spectrogram\n",
    "desired_width = 224\n",
    "desired_height = 224\n",
    "external_spectrogram_resized = cv2.resize(external_spectrogram, (desired_width, desired_height))\n",
    "external_spectrogram_normalized = external_spectrogram_resized.astype(np.float32) / 255.0\n",
    "\n",
    "# Reshape the input to match model's input shape (add batch dimension)\n",
    "input_external = np.expand_dims(external_spectrogram_normalized, axis=0)\n",
    "\n",
    "# Use the trained model to predict classes for the external spectrogram\n",
    "predictions = siamese_model.predict([input_external, input_external])\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "\n",
    "# Print the predicted class label\n",
    "print(\"Predicted class:\", classes[predicted_class_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Assuming y_test and y_pred_proba are defined, and num_classes is the number of classes\n",
    "# Binarize the output for multi-class ROC\n",
    "y_pred_proba = siamese_model.predict([x_test, x_test])\n",
    "y_test_bin = label_binarize(y_test, classes=np.arange(num_classes))\n",
    "\n",
    "# Compute micro-average ROC curve and AUC\n",
    "fpr_micro, tpr_micro, _ = roc_curve(y_test_bin.ravel(), y_pred_proba.ravel())\n",
    "roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
    "\n",
    "# Plot micro-average ROC curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr_micro, tpr_micro, color='blue', lw=2,\n",
    "         label='Micro-average ROC curve (AUC = %0.2f)' % roc_auc_micro)\n",
    "\n",
    "# Plot diagonal line for random guessing\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "# Set limits and labels\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Micro-average Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roc.png', dpi= 650)\n",
    "plt.show()\n",
    "\n",
    "# Print overall micro-average AUC\n",
    "# print(f'Micro-average AUC: {roc_auc_micro:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# **10: Accuracy Curve**\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract training and validation accuracy from history\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Plot accuracy curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), train_accuracy, label='Training Accuracy')\n",
    "plt.plot(range(1, epochs + 1), val_accuracy, label='Validation Accuracy')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('acc.png', dpi=650)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the path to the new dataset directory\n",
    "data_dir = 'path to dataset folder'\n",
    "\n",
    "# Load the dataset from the directory\n",
    "# Assuming the directory has subdirectories representing each class\n",
    "def load_dataset(data_dir, img_size=(224, 224)):\n",
    "    class_names = os.listdir(data_dir)  # List of class names\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterate through each class directory\n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            img = cv2.imread(img_path)  # Read image\n",
    "            img = cv2.resize(img, img_size)  # Resize image\n",
    "            img = img.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "            images.append(img)\n",
    "            labels.append(class_idx)  # Assign class index as label\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Shuffle the dataset\n",
    "    indices = np.arange(images.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    images = images[indices]\n",
    "    labels = labels[indices]\n",
    "\n",
    "    return images, labels, class_names\n",
    "\n",
    "# Load the dataset\n",
    "x_data, y_data, classes = load_dataset(data_dir)\n",
    "\n",
    "# Split the data into training, validation, and test sets (e.g., 80-10-10 split)\n",
    "train_split = int(0.8 * len(x_data))\n",
    "val_split = int(0.10 * len(x_data))\n",
    "x_train, y_train = x_data[:train_split], y_data[:train_split]\n",
    "x_val, y_val = x_data[train_split:train_split + val_split], y_data[train_split:train_split + val_split]\n",
    "x_test, y_test = x_data[train_split + val_split:], y_data[train_split + val_split:]\n",
    "\n",
    "# Load the saved Siamese model\n",
    "model_path = 'path to saved model'\n",
    "siamese_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_proba = siamese_model.predict([x_test, x_test])\n",
    "y_pred_classes = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Compute overall metrics\n",
    "overall_accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "overall_f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "overall_precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
    "overall_recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "# Print overall metrics\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "print(f\"Overall Precision: {overall_precision:.4f}\")\n",
    "print(f\"Overall Recall: {overall_recall:.4f}\")\n",
    "print(f\"Overall F1-Score: {overall_f1:.4f}\\n\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Initialize lists to store metrics for each class\n",
    "class_wise_accuracy = []\n",
    "class_wise_f1 = []\n",
    "class_wise_precision = []\n",
    "class_wise_recall = []\n",
    "\n",
    "# Calculate metrics for each class\n",
    "for i in range(len(classes)):\n",
    "    true_positives = conf_matrix[i, i]\n",
    "    false_positives = np.sum(conf_matrix[:, i]) - true_positives\n",
    "    false_negatives = np.sum(conf_matrix[i, :]) - true_positives\n",
    "    true_negatives = np.sum(conf_matrix) - (true_positives + false_positives + false_negatives)\n",
    "    \n",
    "    # Class-wise accuracy\n",
    "    class_accuracy = (true_positives + true_negatives) / np.sum(conf_matrix)\n",
    "    class_wise_accuracy.append(class_accuracy)\n",
    "    \n",
    "    # Class-wise precision, recall, and F1 score\n",
    "    class_precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    class_recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    class_f1 = 2 * (class_precision * class_recall) / (class_precision + class_recall) if (class_precision + class_recall) > 0 else 0\n",
    "    \n",
    "    class_wise_precision.append(class_precision)\n",
    "    class_wise_recall.append(class_recall)\n",
    "    class_wise_f1.append(class_f1)\n",
    "\n",
    "# Print the table with metrics for each class\n",
    "print(f\"{'Class':<15}{'Accuracy':<12}{'Precision':<12}{'Recall':<12}{'F1-Score':<12}\")\n",
    "print('-' * 60)\n",
    "for i in range(len(classes)):\n",
    "    print(f\"{classes[i]:<15}{class_wise_accuracy[i]:<12.4f}{class_wise_precision[i]:<12.4f}{class_wise_recall[i]:<12.4f}{class_wise_f1[i]:<12.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the path to the new dataset directory\n",
    "data_dir = 'path to dataset folder'\n",
    "\n",
    "# Load the dataset from the directory\n",
    "# Assuming the directory has subdirectories representing each class\n",
    "def load_dataset(data_dir, img_size=(224, 224)):\n",
    "    class_names = os.listdir(data_dir)  # List of class names\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterate through each class directory\n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            img = cv2.imread(img_path)  # Read image\n",
    "            img = cv2.resize(img, img_size)  # Resize image\n",
    "            img = img.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "            images.append(img)\n",
    "            labels.append(class_idx)  # Assign class index as label\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Shuffle the dataset\n",
    "    indices = np.arange(images.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    images = images[indices]\n",
    "    labels = labels[indices]\n",
    "\n",
    "    return images, labels, class_names\n",
    "\n",
    "# Load the dataset\n",
    "x_data, y_data, classes = load_dataset(data_dir)\n",
    "\n",
    "# Split the data into training, validation, and test sets (e.g., 80-10-10 split)\n",
    "train_split = int(0.8 * len(x_data))\n",
    "val_split = int(0.10 * len(x_data))\n",
    "x_train, y_train = x_data[:train_split], y_data[:train_split]\n",
    "x_val, y_val = x_data[train_split:train_split + val_split], y_data[train_split:train_split + val_split]\n",
    "x_test, y_test = x_data[train_split + val_split:], y_data[train_split + val_split:]\n",
    "\n",
    "# Load the saved Siamese model\n",
    "model_path = '/content/siamese_ecg_prod/siamese_cnn/model1.keras'\n",
    "siamese_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_proba = siamese_model.predict([x_test, x_test])\n",
    "y_pred_classes = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Compute overall metrics\n",
    "overall_accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "overall_f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "overall_precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
    "overall_recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "# Print overall metrics\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "print(f\"Overall Precision: {overall_precision:.4f}\")\n",
    "print(f\"Overall Recall: {overall_recall:.4f}\")\n",
    "print(f\"Overall F1-Score: {overall_f1:.4f}\\n\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Initialize lists to store metrics for each class\n",
    "class_wise_accuracy = []\n",
    "class_wise_f1 = []\n",
    "class_wise_precision = []\n",
    "class_wise_recall = []\n",
    "\n",
    "# Calculate metrics for each class\n",
    "for i in range(len(classes)):\n",
    "    true_positives = conf_matrix[i, i]\n",
    "    false_positives = np.sum(conf_matrix[:, i]) - true_positives\n",
    "    false_negatives = np.sum(conf_matrix[i, :]) - true_positives\n",
    "    true_negatives = np.sum(conf_matrix) - (true_positives + false_positives + false_negatives)\n",
    "    \n",
    "    # Class-wise accuracy\n",
    "    class_accuracy = (true_positives + true_negatives) / np.sum(conf_matrix)\n",
    "    class_wise_accuracy.append(class_accuracy)\n",
    "    \n",
    "    # Class-wise precision, recall, and F1 score\n",
    "    class_precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    class_recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    class_f1 = 2 * (class_precision * class_recall) / (class_precision + class_recall) if (class_precision + class_recall) > 0 else 0\n",
    "    \n",
    "    class_wise_precision.append(class_precision)\n",
    "    class_wise_recall.append(class_recall)\n",
    "    class_wise_f1.append(class_f1)\n",
    "\n",
    "# Print the table with metrics for each class\n",
    "print(f\"{'Class':<15}{'Accuracy':<12}{'Precision':<12}{'Recall':<12}{'F1-Score':<12}\")\n",
    "print('-' * 60)\n",
    "for i in range(len(classes)):\n",
    "    print(f\"{classes[i]:<15}{class_wise_accuracy[i]:<12.4f}{class_wise_precision[i]:<12.4f}{class_wise_recall[i]:<12.4f}{class_wise_f1[i]:<12.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_curve, auc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the path to the new dataset directory\n",
    "data_dir = 'path/to/dataset/folder'\n",
    "\n",
    "# Load the dataset from the directory\n",
    "def load_dataset(data_dir, img_size=(224, 224)):\n",
    "    class_names = os.listdir(data_dir)  # List of class names\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterate through each class directory\n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            img = cv2.imread(img_path)  # Read image\n",
    "            img = cv2.resize(img, img_size)  # Resize image\n",
    "            img = img.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "            images.append(img)\n",
    "            labels.append(class_idx)  # Assign class index as label\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels, class_names\n",
    "\n",
    "# Load the dataset\n",
    "x_data, y_data, classes = load_dataset(data_dir)\n",
    "\n",
    "# Initialize KFold with k=7\n",
    "kf = KFold(n_splits=7, shuffle=True)\n",
    "\n",
    "# Load the saved Siamese model\n",
    "model_path = 'path to saved model'\n",
    "\n",
    "# Lists to store the overall metrics for each fold\n",
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "# Initialize lists for ROC curve and AUC\n",
    "all_fpr = []\n",
    "all_tpr = []\n",
    "all_auc = []\n",
    "\n",
    "# Loop over each fold\n",
    "fold_num = 1\n",
    "for train_index, test_index in kf.split(x_data):\n",
    "    print(f\"Fold {fold_num}:\")\n",
    "\n",
    "    # Split the data into training and test sets for this fold\n",
    "    x_train, x_test = x_data[train_index], x_data[test_index]\n",
    "    y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "    # Load the model fresh for each fold (to ensure independent training)\n",
    "    siamese_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_proba = siamese_model.predict([x_test, x_test])\n",
    "    y_pred_classes = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    overall_accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    overall_f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "    overall_precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
    "    overall_recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "    # Print overall metrics\n",
    "    print(f\"Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"Precision: {overall_precision:.4f}\")\n",
    "    print(f\"Recall: {overall_recall:.4f}\")\n",
    "    print(f\"F1-Score: {overall_f1:.4f}\\n\")\n",
    "\n",
    "    # Store the metrics for this fold\n",
    "    fold_accuracies.append(overall_accuracy)\n",
    "    fold_precisions.append(overall_precision)\n",
    "    fold_recalls.append(overall_recall)\n",
    "    fold_f1_scores.append(overall_f1)\n",
    "\n",
    "    # Compute ROC curve and AUC for the fold\n",
    "    y_test_bin = tf.keras.utils.to_categorical(y_test, num_classes=len(classes))\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin.ravel(), y_pred_proba.ravel())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Store ROC curve data\n",
    "    all_fpr.append(fpr)\n",
    "    all_tpr.append(tpr)\n",
    "    all_auc.append(roc_auc)\n",
    "\n",
    "    fold_num += 1\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for i in range(len(all_fpr)):\n",
    "    plt.plot(all_fpr[i], all_tpr[i], label=f'ROC Fold {i + 1} (AUC = {all_auc[i]:.4f})')\n",
    "\n",
    "# Plot formatting\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line (random performance)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curves for each fold')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('kcross_roc.png', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average metrics across all folds\n",
    "avg_accuracy = np.mean(fold_accuracies)\n",
    "avg_precision = np.mean(fold_precisions)\n",
    "avg_recall = np.mean(fold_recalls)\n",
    "avg_f1_score = np.mean(fold_f1_scores)\n",
    "\n",
    "# Print average metrics across all folds\n",
    "print(\"Average Metrics across all folds:\")\n",
    "print(f\"Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"Precision: {avg_precision:.4f}\")\n",
    "print(f\"Recall: {avg_recall:.4f}\")\n",
    "print(f\"F1-Score: {avg_f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the saved Siamese model\n",
    "model_path = 'path to saved model'\n",
    "siamese_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Predict on the entire dataset\n",
    "y_pred_proba = siamese_model.predict([x_data, x_data])\n",
    "y_pred_classes = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_true_bin = tf.keras.utils.to_categorical(y_data, num_classes=len(classes))\n",
    "\n",
    "# Compute Precision-Recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_true_bin.ravel(), y_pred_proba.ravel())\n",
    "avg_precision = average_precision_score(y_true_bin, y_pred_proba, average=\"weighted\")\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(recall, precision, label=f'Precision-Recall curve (AP = {avg_precision:.4f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('overall_pr_curve.png', dpi=650)\n",
    "plt.show()\n",
    "\n",
    "# Print Average Precision\n",
    "print(f'Average Precision: {avg_precision:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
